% \documentclass[10pt, a4paper]{SimpleNotes}
% \documentclass[10pt, a4paper, twocolumn]{SimpleNotes}
% \documentclass[10pt, a4paper, twocolumn]{ResearchNotes}
 \documentclass[11pt, a4paper, top=4cm,bottom=3.5cm, right=3cm,left=3cm]{ResearchNotes}
%  \documentclass[11pt, a4paper, top=3.5cm,bottom=3.5cm, right=3cm,left=3cm]{SimpleNotes}
%\usepackage[latin1]{inputenc} %for other languages but english
%\usepackage[spanish]{babel}
\doctype{Research Notes:}
\title{Introduction to Dynamic Spatio-Temporal Models}
\titleshort{Dynamic Spatio-Temporal Models}
\author{Erick A. Chacon-Montalvan\textsuperscript{1,2}, Erick A. Chacon-Montalvan\textsuperscript{2}, Erick A. Chacon-Montalvan\textsuperscript{3}, Erick A. Chacon-Montalvan\textsuperscript{3}}
\authorfoot{Research student: Erick A. Chacon-Montalvan}
\institute{\textsuperscript{1}\textit{CHICAS, Medical School, Lancaster University, Lancaster, United Kingdom}\\
\textsuperscript{2}\textit{CHICAS, Medical School, Lancaster University, Lancaster, United Kingdom}
}
\date{\today}
\abstract[Abstract:]{In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success. For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any.In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success. For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any.}
\keywords[Keywords:]{Spatio-temporal, Climate variability, Malaria prevalence, geostatistics, matern}
% Do not delete the next line, just let the attributes empty
% in case you do not want to provide logos.
% \logos{chicas-new}{medical-school}
\logos{chicas}{medical-school}
% Defining own colors of the template.
\definecolor{main_color}{RGB}{181,18,27}
% \definecolor{main_color}{RGB}{0,0,0}
\colorlet{tit_color}{main_color!80!black}
\colorlet{box_color}{main_color!10}
\colorlet{type_color}{black!60}
\colors{main_color}{tit_color}{box_color}{type_color}
% If desired, the basic colors can be put directly with next sentence.
%\colors{black}{black}{white}{black}

% \linespread{2}
\begin{document}
\maketitle

\section{Introduction}
In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success.
In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success.

In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success.
In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success.
In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success.
In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success.
In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success.

\begin{sframe}{box_color}
  \textbf{Statement}:\\
\begin{equation}
  \label{eq:bla}
~~p(y>r|\theta)=(1-\theta)^r,
\end{equation}
where $r = 1,2,...$
\end{sframe}

\begin{sframe}{white}
\textbf{Proof}:
\[p(y>r|\theta)=1-p(y\leq r|\theta)\]

\[p(y>r|\theta)=1-\sum\limits_{k=1}^{r}(1-\theta)^{k-1}\theta\]

\[p(y>r|\theta)=1-\theta\sum\limits_{k=1}^{r}(1-\theta)^{k-1}\]
\[p(y>r|\theta)=1-\theta\bigg[\frac{1-(1-\theta)^r}{1-(1-\theta)}\bigg]\]
\[p(y>r|\theta)=1-\theta\bigg[\frac{1-(1-\theta)^r}{\theta}\bigg]\]
\[p(y>r|\theta)=1-[1-(1-\theta)^r]=(1-\theta)^r\fp\]
\end{sframe}

For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any other $x_j$, (ii). They are identically distributed $x_i\sim\theta^{x_i}(1-\theta)^{1-x_i}$, where $i =1,2,...$. (iii) The variance is greater than the mean. For this reason is used in overdispersed countable data. (iv) This distribution is unimodal.

For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any other $x_j$, (ii). They are identically distributed $x_i\sim\theta^{x_i}(1-\theta)^{1-x_i}$, where $i =1,2,...$. (iii) The variance is greater than the mean. For this reason is used in overdispersed countable data. (iv) This distribution is unimodal.

For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any other $x_j$, (ii). They are identically distributed $x_i\sim\theta^{x_i}(1-\theta)^{1-x_i}$, where $i =1,2,...$. (iii) The variance is greater than the mean. For this reason is used in overdispersed countable data. (iv) This distribution is unimodal.

For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any other $x_j$, (ii). They are identically distributed $x_i\sim\theta^{x_i}(1-\theta)^{1-x_i}$, where $i =1,2,...$. (iii) The variance is greater than the mean. For this reason is used in overdispersed countable data. (iv) This distribution is unimodal.

In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success. For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any other $x_j$, (ii). They are identically distributed $x_i\sim\theta^{x_i}(1-\theta)^{1-x_i}$, where $i =1,2,...$. (iii) The variance is greater than the mean. For this reason is used in overdispersed countable data. (iv) This distribution is unimodal.
\section{Section 2}
In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success. For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any other $x_j$, (ii) They are identically distributed $x_i\sim\theta^{x_i}(1-\theta)^{1-x_i}$, where $i =1,2,...$. (iii) The variance is greater than the mean. For this reason is used in overdispersed countable data. (iv) This distribution is unimodal.
\section{Section 1}
In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success. For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any other $x_j$, (ii) They are identically distributed $x_i\sim\theta^{x_i}(1-\theta)^{1-x_i}$, where $i =1,2,...$. (iii) The variance is greater than the mean. For this reason is used in overdispersed countable data. (iv) This distribution is unimodal.
\section{Section 1}
In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success. For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any other $x_j$, (ii) They are identically distributed $x_i\sim\theta^{x_i}(1-\theta)^{1-x_i}$, where $i =1,2,...$. (iii) The variance is greater than the mean. For this reason is used in overdispersed countable data. (iv) This distribution is unimodal.
\section{Section 1}
In the geometric distribution, $\theta$ represents the probability of succes in each trial. Furthermore, it should follow that $y$ is countable and greater than one. In general, in the negative binomial distribution, $y$ is the number of trials until get the $k$ first success. For this reason, the negative binomial distribution has certain assumptions considering that each event come from a Bernoulli distribution.(i) Each $x_i$ is independent of any other $x_j$, (ii) They are identically distributed $x_i\sim\theta^{x_i}(1-\theta)^{1-x_i}$, where $i =1,2,...$. (iii) The variance is greater than the mean. For this reason is used in overdispersed countable data. (iv) This distribution is unimodal.

% \begin{thebibliography}{9}
% \bibitem{lamport94}
%  Leslie Lamport,
%  \emph{\LaTeX: a document preparation system},
%  Addison Wesley, Massachusetts,
%  2nd edition,
%  1994.
% \end{thebibliography}

%\nocite{Resource1}
%\nocite{Resource2}
% \nocite{*}
\bibliographystyle{alpha}
%\bibliography{resourcesclass1}
%\addbibresource{resourcesclass1.bib}
%\printbibliography
\end{document}
